{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcf3eea8-5beb-472d-9860-6ee72e562dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset...\n",
      "[INFO] Raw columns: ['text', 'sentiment_label']\n",
      "[INFO] Building TF-IDF features...\n",
      "[INFO] Adding lexicon sentiment features...\n",
      "[INFO] Training Sentiment Classifier...\n",
      "[RESULT] Sentiment Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.78      0.88         9\n",
      "     neutral       0.86      1.00      0.92        12\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.93      0.89      0.90        21\n",
      "weighted avg       0.92      0.90      0.90        21\n",
      "\n",
      "[INFO] Training Escalation Risk Model...\n",
      "[LightGBM] [Info] Number of positive: 34, number of negative: 47\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 106\n",
      "[LightGBM] [Info] Number of data points in the train set: 81, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.419753 -> initscore=-0.323787\n",
      "[LightGBM] [Info] Start training from score -0.323787\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[RESULT] Escalation Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.58      0.70        12\n",
      "           1       0.62      0.89      0.73         9\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.75      0.74      0.71        21\n",
      "weighted avg       0.76      0.71      0.71        21\n",
      "\n",
      "[INFO] Running inference on full dataset...\n",
      "[INFO] Generating insights...\n",
      "[INFO] Plotting visuals...\n",
      "[INFO] Saving H5...\n",
      "[INFO] Saving metadata YAML...\n",
      "[DONE] All artifacts saved to C:\\Users\\NXTWAVE\\Downloads\\Customer Support Call Sentiment & Escalation Predictor\n"
     ]
    }
   ],
   "source": [
    "# callsense_pipeline_tfidf_fixed.py\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import h5py\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import lightgbm as lgb\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\", quiet=True)\n",
    "\n",
    "# -------- CONFIG --------\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\Customer Support Call Sentiment & Escalation Predictor\"\n",
    "DATA_CSV = os.path.join(BASE_DIR, \"archive\", \"customer_call_transcriptions.csv\")\n",
    "\n",
    "OUT_SENTIMENT_MODEL = os.path.join(BASE_DIR, \"sentiment_model.pkl\")\n",
    "OUT_ESCALATION_MODEL = os.path.join(BASE_DIR, \"escalation_model.pkl\")\n",
    "OUT_H5 = os.path.join(BASE_DIR, \"processed_calls.h5\")\n",
    "OUT_JSON = os.path.join(BASE_DIR, \"insights.json\")\n",
    "OUT_YAML = os.path.join(BASE_DIR, \"build_metadata.yaml\")\n",
    "OUT_PRED = os.path.join(BASE_DIR, \"predictions.csv\")\n",
    "VISUAL_DIR = os.path.join(BASE_DIR, \"visuals\")\n",
    "\n",
    "os.makedirs(VISUAL_DIR, exist_ok=True)\n",
    "\n",
    "# -------- LOAD DATA --------\n",
    "print(\"[INFO] Loading dataset...\")\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "print(\"[INFO] Raw columns:\", list(df.columns))\n",
    "\n",
    "# -------- SYNTHETIC COLUMNS --------\n",
    "df = df.rename(columns={\"text\": \"transcript\", \"sentiment_label\": \"sentiment\"})\n",
    "df[\"call_id\"] = [f\"call_{i}\" for i in range(len(df))]\n",
    "df[\"customer_id\"] = [f\"cust_{i%50}\" for i in range(len(df))]\n",
    "df[\"agent_id\"] = [f\"agent_{i%10}\" for i in range(len(df))]\n",
    "df[\"duration\"] = np.random.randint(60, 600, size=len(df))\n",
    "df[\"resolution_status\"] = np.where(df[\"sentiment\"]==\"negative\", \"escalated\", \"resolved\")\n",
    "df[\"escalation\"] = df[\"resolution_status\"].apply(lambda x: 1 if x==\"escalated\" else 0)\n",
    "\n",
    "# -------- FEATURES (TF-IDF + Lexicon) --------\n",
    "print(\"[INFO] Building TF-IDF features...\")\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "X_tfidf = tfidf.fit_transform(df[\"transcript\"]).toarray()\n",
    "\n",
    "print(\"[INFO] Adding lexicon sentiment features...\")\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "lex = np.array([list(sia.polarity_scores(t).values()) for t in df[\"transcript\"]])\n",
    "\n",
    "X = np.concatenate([X_tfidf, lex], axis=1)\n",
    "\n",
    "# -------- LABELS --------\n",
    "le_sent = LabelEncoder()\n",
    "y_sent = le_sent.fit_transform(df[\"sentiment\"])\n",
    "y_esc = df[\"escalation\"].astype(int).values\n",
    "\n",
    "# -------- TRAIN SENTIMENT MODEL --------\n",
    "print(\"[INFO] Training Sentiment Classifier...\")\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y_sent, test_size=0.2, random_state=42, stratify=y_sent)\n",
    "clf_sent = LogisticRegression(max_iter=2000)\n",
    "clf_sent.fit(Xtr, ytr)\n",
    "\n",
    "y_pred = clf_sent.predict(Xte)\n",
    "labels = sorted(np.unique(yte))\n",
    "print(\"[RESULT] Sentiment Report:\\n\",\n",
    "      classification_report(yte, y_pred,\n",
    "                            labels=labels,\n",
    "                            target_names=le_sent.classes_[labels]))\n",
    "\n",
    "joblib.dump((clf_sent, le_sent, tfidf), OUT_SENTIMENT_MODEL)\n",
    "\n",
    "# -------- TRAIN ESCALATION MODEL --------\n",
    "print(\"[INFO] Training Escalation Risk Model...\")\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y_esc, test_size=0.2, random_state=42, stratify=y_esc)\n",
    "clf_esc = lgb.LGBMClassifier()\n",
    "clf_esc.fit(Xtr, ytr)\n",
    "y_pred = clf_esc.predict(Xte)\n",
    "print(\"[RESULT] Escalation Report:\\n\", classification_report(yte, y_pred))\n",
    "\n",
    "joblib.dump(clf_esc, OUT_ESCALATION_MODEL)\n",
    "\n",
    "# -------- PREDICTIONS --------\n",
    "print(\"[INFO] Running inference on full dataset...\")\n",
    "sent_preds = clf_sent.predict(X)\n",
    "sent_probs = clf_sent.predict_proba(X).max(axis=1)\n",
    "esc_probs = clf_esc.predict_proba(X)[:,1]\n",
    "\n",
    "df_out = df.copy()\n",
    "df_out[\"sentiment_pred\"] = le_sent.inverse_transform(sent_preds)\n",
    "df_out[\"sentiment_conf\"] = sent_probs\n",
    "df_out[\"escalation_prob\"] = esc_probs\n",
    "df_out.to_csv(OUT_PRED, index=False)\n",
    "\n",
    "# -------- INSIGHTS --------\n",
    "print(\"[INFO] Generating insights...\")\n",
    "insights = {\n",
    "    \"top_escalation_customers\": df_out.groupby(\"customer_id\")[\"escalation_prob\"].mean().sort_values(ascending=False).head(5).to_dict(),\n",
    "    \"agent_escalation_rates\": df_out.groupby(\"agent_id\")[\"escalation_prob\"].mean().to_dict(),\n",
    "    \"sentiment_distribution\": df_out[\"sentiment_pred\"].value_counts().to_dict()\n",
    "}\n",
    "with open(OUT_JSON, \"w\") as f: json.dump(insights, f, indent=2)\n",
    "\n",
    "# -------- VISUALS --------\n",
    "print(\"[INFO] Plotting visuals...\")\n",
    "cm = confusion_matrix(yte, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Escalation Confusion Matrix\")\n",
    "plt.savefig(os.path.join(VISUAL_DIR, \"escalation_confusion_matrix.png\"))\n",
    "plt.close()\n",
    "\n",
    "pivot = df_out.pivot_table(index=\"agent_id\", values=\"escalation_prob\", aggfunc=\"mean\")\n",
    "sns.heatmap(pivot, annot=True, cmap=\"Reds\")\n",
    "plt.title(\"Escalation Risk Heatmap (by agent)\")\n",
    "plt.savefig(os.path.join(VISUAL_DIR, \"escalation_risk_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "sent_trend = df_out.groupby(df_out.index // 10)[\"sentiment_pred\"].apply(lambda x: (x==\"negative\").mean())\n",
    "sent_trend.plot()\n",
    "plt.title(\"Sentiment Trend (chunks of 10 calls)\")\n",
    "plt.ylabel(\"Fraction Negative\")\n",
    "plt.savefig(os.path.join(VISUAL_DIR, \"sentiment_trends.png\"))\n",
    "plt.close()\n",
    "\n",
    "# -------- SAVE H5 --------\n",
    "print(\"[INFO] Saving H5...\")\n",
    "with h5py.File(OUT_H5, \"w\") as f:\n",
    "    f.create_dataset(\"features\", data=X)\n",
    "    f.create_dataset(\"sentiment_labels\", data=y_sent)\n",
    "    f.create_dataset(\"escalation_labels\", data=y_esc)\n",
    "\n",
    "# -------- SAVE YAML --------\n",
    "print(\"[INFO] Saving metadata YAML...\")\n",
    "meta = {\n",
    "    \"dataset\": DATA_CSV,\n",
    "    \"records\": len(df),\n",
    "    \"features_dim\": X.shape[1],\n",
    "    \"models\": {\n",
    "        \"sentiment_model\": OUT_SENTIMENT_MODEL,\n",
    "        \"escalation_model\": OUT_ESCALATION_MODEL\n",
    "    },\n",
    "    \"artifacts\": {\n",
    "        \"predictions\": OUT_PRED,\n",
    "        \"insights\": OUT_JSON,\n",
    "        \"visuals\": VISUAL_DIR\n",
    "    }\n",
    "}\n",
    "with open(OUT_YAML, \"w\") as f: yaml.dump(meta, f)\n",
    "\n",
    "print(\"[DONE] All artifacts saved to\", BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ed43d-420b-4bab-9a66-212adc668d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
